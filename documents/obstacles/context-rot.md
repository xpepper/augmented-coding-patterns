---
authors: [lada_kesseler, steve_kuo]
---

# Context Rot <Dementia> (Obstacle)

## Description
Context degrades as the conversation grows. The model stops following earlier instructions, and performance drops unpredictably This happens long before you hit the context window limit.

Context doesn't decay evenly; it fades in zones:
- **Focus zone**: Instructions followed reliably
- **Effective context**: Still usable but weakening. Feels productive, yet earlier guidance is starting to be ignored or de-prioritized
- **Red zone**: Past instructions are routinely lost or contradicted.

## Impact
- Earlier instructions lose influence as conversation progresses
- The same question may yield very different results later in the thread
- You can't rely on what the model will remember or follow
- Forces frequent resets to maintain quality
